# graph/training/nodes/train_trial.py
from __future__ import annotations

import json
import os
import uuid
import time
from typing import Any, Dict
from llm.tools.s3_client import download_s3

from llm.graph.training.state import TrainState
import logging

logger = logging.getLogger("uvicorn.error")

# --- RabbitMQ settings ---
RABBITMQ_URL    = os.getenv("RABBITMQ_URL", "amqp://admin:ssafy1234@k13s303.p.ssafy.io:5672/%2F")
# í•™ìŠµ ìš”ì²­ ë³´ë‚¼ exchange (GPU ì„œë²„ main.pyì—ì„œ train í ë°”ì¸ë”©ëœ cmdìš©)
EXCHANGE_CMD = os.getenv("RMQ_EXCHANGE_CMD", "jobs.cmd")

# ì§„í–‰ë¥ /ì™„ë£Œ ì´ë²¤íŠ¸ ë°›ì„ exchange (Progressì—ì„œ ì‚¬ìš©í•˜ëŠ” eventsìš©)
EXCHANGE_EVENTS = os.getenv("RMQ_EXCHANGE_EVENTS", "jobs.events")

RK_START = "train.start"             # í•™ìŠµ ìš”ì²­
RK_HPO = "train.hpo"
RK_DONE_FMT = "job.{job_id}.done"    # ì™„ë£Œ ì´ë²¤íŠ¸ routing key
RK_ERROR_FMT = "job.{job_id}.error"
RK_STATUS_FMT = "job.{job_id}.status"
S3_BUCKET = os.getenv("S3_BUCKET", "visioninapp-bucket")

# ------------------------ ìœ í‹¸ ------------------------

def _clean_str(val: Any) -> str | None:
    if val is None:
        return None
    if isinstance(val, str):
        s = val.strip()
        if not s or s.lower() in ("null", "none"):
            return None
        return s
    # strì´ ì•„ë‹ˆì–´ë„ ë“¤ì–´ì˜¤ë©´ ë¬¸ìì—´ë¡œ ìºìŠ¤íŒ…
    s = str(val).strip()
    return s or None


def _select_model_from_params(params: Dict[str, Any]) -> str | None:
    """
    ëª¨ë¸ ì´ë¦„ ì„ íƒ ê·œì¹™:
    1) model
    2) model_name
    3) model_variant
    4) model_varient (ì˜¤íƒ€ ëŒ€ì‘)
    ìœ„ ìˆœì„œëŒ€ë¡œ ìœ íš¨í•œ ê°’ì„ ì°¾ëŠ”ë‹¤.
    """
    for key in ("model", "model_name", "model_variant"):
        v = _clean_str(params.get(key))
        if v:
            return v
    return None

def _merge_train_params(state: TrainState) -> Dict[str, Any]:
    cfg = state.train_cfg or {}

    base = (cfg.get("train") or {}).copy()
    best = ((state.best_trial or {}).get("params") or {}).copy()
    over = (state.train_overrides or {}).copy()

    # ë¨¼ì € base/best/overë¥¼ í•œ ë° í•©ì¹˜ê³ 
    merged = {**base, **best, **over}

    # ğŸ”¹ ì—¬ê¸°ì„œ ëª¨ë¸ ì´ë¦„ì„ ì•ˆì •ì ìœ¼ë¡œ ë½‘ëŠ”ë‹¤
    selected_model = _select_model_from_params(merged)
    if selected_model:
        merged["model"] = selected_model
    else:
        # ìœ íš¨í•œ ê°’ì´ ì§„ì§œë¡œ í•˜ë‚˜ë„ ì—†ì„ ë•Œë§Œ ê¸°ë³¸ê°’ ì‚¬ìš©
        merged["model"] = "yolo12n"

    # ê¸°ë³¸ê°’ë“¤ (ì´ë¯¸ ê°’ ìˆìœ¼ë©´ ê±´ë“¤ì§€ ì•ŠìŒ)
    merged.setdefault("epochs", 100)
    merged.setdefault("batch", 16)
    merged.setdefault("imgsz", 640)

    # None / "null" ë“±ì€ ê¹”ë”í•˜ê²Œ ì œê±°
    cleaned = {}
    for k, v in merged.items():
        if isinstance(v, str):
            vv = v.strip()
            if not vv or vv.lower() in ("null", "none"):
                continue
            cleaned[k] = vv
        elif v is not None:
            cleaned[k] = v

    return cleaned

def _infer_dataset(state: TrainState) -> Dict[str, str]:
    over = state.train_overrides or {}
    if isinstance(over.get("dataset"), dict):
        ds = over["dataset"]
        name = str(ds.get("name") or "").strip()
        s3_prefix = str(ds.get("s3_prefix") or "").strip()
        if name and s3_prefix:
            return {"name": name, "s3_prefix": s3_prefix}

    cfg = state.train_cfg or {}
    data_cfg = cfg.get("data") or {}
    ver = (state.dataset_version or data_cfg.get("dataset_version") or "").strip()
    name = ver.split("@")[0] if "@" in ver else (ver or "dataset").strip()
    if not name:
        name = "dataset"
    return {"name": name, "s3_prefix": f"datasets/{name}/"}


def _infer_output(state: TrainState, dataset_name: str) -> Dict[str, str]:
    over = state.train_overrides or {}
    if isinstance(over.get("output"), dict):
        out = over["output"]
        prefix = str(out.get("prefix") or "").strip()
        model_name = str(out.get("model_name") or "").strip()
        metrics_name = str(out.get("metrics_name") or "").strip() or "results.csv"
        if prefix and model_name:
            return {"s3_bucket": S3_BUCKET, "prefix": prefix, "model_name": model_name, "metrics_name": metrics_name}

    return {
        "prefix": f"models/{dataset_name}/train",
        "model_name": f"{dataset_name}.pt",
        "metrics_name": "results.csv",
    }


# ------------------- RabbitMQ í†µì‹  -------------------

def _publish_to_rabbitmq(message: Dict[str, Any], rk: str) -> None:
    import pika

    try:
        logger.info(f"[train_trial] RabbitMQ ì—°ê²° ì‹œë„: {RABBITMQ_URL}")
        params = pika.URLParameters(RABBITMQ_URL)
        conn = pika.BlockingConnection(params)
        ch = conn.channel()

        # ìš”ì²­ì€ cmd exchangeë¡œ
        logger.info(f"[train_trial] Exchange ì„ ì–¸: {EXCHANGE_CMD}")
        ch.exchange_declare(exchange=EXCHANGE_CMD, exchange_type="topic", durable=True)

        body = json.dumps(message, ensure_ascii=False).encode("utf-8")
        logger.info(f"[train_trial] ë©”ì‹œì§€ ë°œí–‰: exchange={EXCHANGE_CMD}, routing_key={RK_START}")
        ch.basic_publish(
            exchange=EXCHANGE_CMD,
            routing_key=rk,
            body=body,
            properties=pika.BasicProperties(
                delivery_mode=2,
                content_type="application/json",
            ),
        )
        conn.close()
        logger.info(f"[train_trial] âœ… ë©”ì‹œì§€ ë°œí–‰ ì™„ë£Œ")
    except Exception as e:
        logger.info(f"[train_trial] âŒ RabbitMQ ë©”ì‹œì§€ ë°œí–‰ ì‹¤íŒ¨: {e}")
        raise



def _wait_for_done(job_id: str, timeout_sec: int = 21600) -> Dict[str, Any]:
    """
    GPU ì„œë²„ì—ì„œ ì „ì†¡í•˜ëŠ” job.{job_id}.done / job.{job_id}.error / job.{job_id}.status ì´ë²¤íŠ¸ë¥¼ ì²˜ë¦¬.
    - done: ì„±ê³µìœ¼ë¡œ ì¢…ë£Œ
    - error: ì¦‰ì‹œ ì‹¤íŒ¨ë¡œ ì¢…ë£Œ
    - status/progress: ì§„í–‰ë¥  ë¡œê·¸ë§Œ ë‚¨ê¸°ê³  ê³„ì† ëŒ€ê¸°
    """
    import pika

    try:
        logger.info(f"[train_trial] ì™„ë£Œ ì´ë²¤íŠ¸ ëŒ€ê¸° ì‹œì‘: job_id={job_id}, timeout={timeout_sec}ì´ˆ")
        params = pika.URLParameters(RABBITMQ_URL)
        conn = pika.BlockingConnection(params)
        ch = conn.channel()

        logger.info(f"[train_trial] Exchange ì„ ì–¸: {EXCHANGE_EVENTS}")
        ch.exchange_declare(exchange=EXCHANGE_EVENTS, exchange_type="topic", durable=True)

        q = ch.queue_declare(queue="", exclusive=True, auto_delete=True)
        qname = q.method.queue

        rk_done = RK_DONE_FMT.format(job_id=job_id)
        rk_error = RK_ERROR_FMT.format(job_id=job_id)
        rk_status = RK_STATUS_FMT.format(job_id=job_id)

        # âœ… ì„±ê³µ / ì‹¤íŒ¨ / ì§„í–‰ë¥  ëª¨ë‘ êµ¬ë…
        logger.info(f"[train_trial] í ë°”ì¸ë”©: {qname} <- {rk_done}")
        ch.queue_bind(exchange=EXCHANGE_EVENTS, queue=qname, routing_key=rk_done)
        logger.info(f"[train_trial] í ë°”ì¸ë”©: {qname} <- {rk_error}")
        ch.queue_bind(exchange=EXCHANGE_EVENTS, queue=qname, routing_key=rk_error)
        logger.info(f"[train_trial] í ë°”ì¸ë”©: {qname} <- {rk_status}")
        ch.queue_bind(exchange=EXCHANGE_EVENTS, queue=qname, routing_key=rk_status)

        deadline = time.monotonic() + timeout_sec
        result_payload: Dict[str, Any] | None = None
        last_log = time.monotonic()

        for method, properties, body in ch.consume(qname, inactivity_timeout=1.0):
            now = time.monotonic()

            # ì£¼ê¸° ë¡œê·¸
            if now - last_log >= 10:
                remain = max(0, int(deadline - now))
                logger.info(f"[train_trial] ëŒ€ê¸° ì¤‘... (ë‚¨ì€ ì‹œê°„: {remain}ì´ˆ)")
                last_log = now

            # inactivity_timeout: ë©”ì‹œì§€ ì—†ìŒ
            if method is None:
                if now > deadline:
                    logger.info(f"[train_trial] â° íƒ€ì„ì•„ì›ƒ: {timeout_sec}ì´ˆ ê²½ê³¼")
                    break
                continue

            raw = body.decode("utf-8", errors="replace")

            try:
                data = json.loads(raw)
            except Exception as e:
                logger.info(f"[train_trial] âš ï¸ JSON íŒŒì‹± ì˜¤ë¥˜: {e}, body={raw!r}")
                # JSON ê¹¨ì¡Œìœ¼ë©´ ì´ jobì€ ì‹¤íŒ¨ ì²˜ë¦¬
                result_payload = {
                    "job_id": job_id,
                    "event": "error",
                    "status": "error",
                    "error": f"invalid JSON from GPU server: {e}",
                }
                ch.basic_ack(method.delivery_tag)
                break

            msg_job_id = str(data.get("job_id") or "")
            event = (data.get("event") or data.get("status") or "").lower()
            rk = method.routing_key

            logger.info(f"[train_trial] ì´ë²¤íŠ¸ ìˆ˜ì‹ : rk={rk}, event={event}, data={data}")

            # ğŸ”¹ ë‹¤ë¥¸ job_idë©´ ë¬´ì‹œ
            if msg_job_id and msg_job_id != job_id:
                ch.basic_ack(method.delivery_tag)
                continue

            # ğŸ”¹ ì§„í–‰ë¥  ì´ë²¤íŠ¸: status/progress
            if rk == rk_status or event in ("progress", "status"):
                epoch = data.get("epoch")
                total = data.get("total_epochs")
                if epoch is not None and total is not None:
                    logger.info(f"[train_trial] ì§„í–‰ë¥ : {epoch}/{total} epoch ì™„ë£Œ")
                else:
                    logger.info(f"[train_trial] ì§„í–‰ë¥  ì´ë²¤íŠ¸ ìˆ˜ì‹ : {data}")
                ch.basic_ack(method.delivery_tag)
                continue  # ê³„ì† ë‹¤ìŒ ë©”ì‹œì§€ ëŒ€ê¸°

            # ğŸ”¹ ì‹¤íŒ¨ ì´ë²¤íŠ¸: error routing key ë˜ëŠ” event == error/failed
            if rk == rk_error or event in ("error", "failed", "train_error"):
                result_payload = {
                    **data,
                    "job_id": msg_job_id or job_id,
                    "event": "error",
                    "status": "error",
                }
                ch.basic_ack(method.delivery_tag)
                break

            # ğŸ”¹ ì„±ê³µ ì´ë²¤íŠ¸: done + event == done
            if rk == rk_done and event == "done":
                status = (data.get("status") or "success").lower()
                result_payload = {
                    **data,
                    "job_id": msg_job_id or job_id,
                    "event": "done",
                    "status": status,
                }
                ch.basic_ack(method.delivery_tag)
                break

            # ğŸ”¹ ê·¸ ì™¸ëŠ” ì†Œë¹„ë§Œ í•˜ê³  ë¬´ì‹œ
            ch.basic_ack(method.delivery_tag)

            if now > deadline:
                logger.info(f"[train_trial] â° íƒ€ì„ì•„ì›ƒ: {timeout_sec}ì´ˆ ê²½ê³¼")
                break

        # ì–¸ë°”ì¸ë”© ë° ì—°ê²° ì¢…ë£Œ
        ch.queue_unbind(exchange=EXCHANGE_EVENTS, queue=qname, routing_key=rk_done)
        ch.queue_unbind(exchange=EXCHANGE_EVENTS, queue=qname, routing_key=rk_error)
        ch.queue_unbind(exchange=EXCHANGE_EVENTS, queue=qname, routing_key=rk_status)
        conn.close()

        # ì•„ë¬´ ê²°ê³¼ë„ ëª» ë°›ìŒ â†’ íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬
        if result_payload is None:
            logger.info(f"[train_trial] âš ï¸ ì™„ë£Œ/ì—ëŸ¬ ì´ë²¤íŠ¸ ë¯¸ìˆ˜ì‹ ")
            return {
                "job_id": job_id,
                "event": "timeout",
                "status": "timeout",
                "error": "no done/error event received",
            }

        return result_payload

    except Exception as e:
        logger.info(f"[train_trial] âŒ ì™„ë£Œ ì´ë²¤íŠ¸ ëŒ€ê¸° ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        return {
            "job_id": job_id,
            "event": "error",
            "status": "error",
            "error": f"_wait_for_done exception: {e}",
        }


# ------------------- ë©”ì¸ ë…¸ë“œ -------------------

def train_trial(state: TrainState) -> TrainState:
    """
    EC2 â†’ GPU í•™ìŠµ ìš”ì²­ ë°œí–‰ ì „ìš©
    ì ˆëŒ€ í•™ìŠµ ìˆ˜í–‰ ê¸ˆì§€. ë©”ì‹œì§€ êµ¬ì¡°ëŠ” GPU ì„œë²„ ìš”êµ¬ì‚¬í•­ì— ë§ì¶¤.
    """
    job_id = state.job_id or str(uuid.uuid4()).replace("-", "")
    merged = _merge_train_params(state)
    ds = _infer_dataset(state)
    out = _infer_output(state, ds["name"])

    # split ì •ë³´ê°€ ìˆìœ¼ë©´ ì¶”ê°€
    over = state.train_overrides or {}

    if "model" not in over:
        if "model_name" in over:
            over["model"] = over["model_name"]
        elif "model_variant" in over:
            over["model"] = over["model_variant"]

    state.train_overrides = over

    split = over.get("split")
    split_seed = over.get("split_seed")
    move_files = over.get("move_files")

    payload = {
        "job_id": job_id,
        "dataset": ds,
        "output": out,
        "hyperparams": merged,     # GPUê°€ í•™ìŠµ ì‹œ ì‚¬ìš©í•  íŒŒë¼ë¯¸í„°
    }

    hpo = {
        "job_id": job_id,
        "hyperparams": merged,
    }

    # optional fields
    if split is not None:
        payload["split"] = split
    if split_seed is not None:
        payload["split_seed"] = split_seed
    if move_files is not None:
        payload["move_files"] = move_files
    logger.info(payload)
    # 1ï¸âƒ£ í•™ìŠµ ìš”ì²­ ë°œí–‰
    logger.info(f"[train_trial] í•™ìŠµ ìš”ì²­ ë°œí–‰ ì‹œì‘: job_id={job_id}")
    _publish_to_rabbitmq(payload, RK_START)
    _publish_to_rabbitmq(hpo, RK_HPO)

    # 2ï¸âƒ£ ì™„ë£Œ ì´ë²¤íŠ¸ ëŒ€ê¸° (job.{job_id}.done)
    wait_sec = int(os.getenv("TRAIN_WAIT_TIMEOUT_SEC", "10800"))
    result = _wait_for_done(job_id, wait_sec)
    logger.info(f"[train_trial] ì™„ë£Œ ì´ë²¤íŠ¸ ëŒ€ê¸° ì¢…ë£Œ: result={result.get('status', 'unknown')}")

    # 3ï¸âƒ£ ê²°ê³¼ ë°˜ì˜
    ctx = state.context or {}
    ctx["train_trial"] = {
        "exchange": EXCHANGE_CMD,
        "rk_start": RK_START,
        "rk_done": RK_DONE_FMT.format(job_id=job_id),
        "payload": payload,
        "result": result,
    }
    state.context = ctx
    state.job_id = job_id

    # 4ï¸âƒ£ ê²°ê³¼ ìƒíƒœ ì •ë¦¬
    event = result.get("event")
    status = result.get("status")

    if event == "done" and status not in ("error", "failed"):
        artifact = result.get("artifact") or {}
        metrics = result.get("metrics") or {}
        state.model_path = artifact.get("model_path") or artifact.get("s3_path")
        state.metrics = metrics
        state.action = "TRAIN_COMPLETED"
        return state

    if status == "timeout":
        state.action = "TRAIN_TIMEOUT"
        state.error = result.get("error") or "no done/error event received"
        return state

    # ê·¸ ì™¸ëŠ” ì „ë¶€ ì‹¤íŒ¨ë¡œ ì²˜ë¦¬ (event == "error" í¬í•¨)
    state.action = "TRAIN_FAILED"
    state.error = result.get("error") or f"train failed: {status or event}"
    return state
