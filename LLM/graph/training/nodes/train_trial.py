# graph/training/nodes/train_trial.py
from __future__ import annotations

import json
import os
import uuid
import time
from typing import Any, Dict
from tools.s3_client import download_s3

from graph.training.state import TrainState

# --- RabbitMQ settings ---
RABBITMQ_URL    = os.getenv("RABBITMQ_URL", "amqp://admin:ssafy1234@k13s303.p.ssafy.io:5672/%2F")
# í•™ìŠµ ìš”ì²­ ë³´ë‚¼ exchange (GPU ì„œë²„ main.pyì—ì„œ train í ë°”ì¸ë”©ëœ cmdìš©)
EXCHANGE_CMD = os.getenv("RMQ_EXCHANGE_CMD", "jobs.cmd")

# ì§„í–‰ë¥ /ì™„ë£Œ ì´ë²¤íŠ¸ ë°›ì„ exchange (Progressì—ì„œ ì‚¬ìš©í•˜ëŠ” eventsìš©)
EXCHANGE_EVENTS = os.getenv("RMQ_EXCHANGE_EVENTS", "jobs.events")

RK_START = "train.start"             # í•™ìŠµ ìš”ì²­
RK_DONE_FMT = "job.{job_id}.done"    # ì™„ë£Œ ì´ë²¤íŠ¸ routing key
S3_BUCKET = os.getenv("S3_BUCKET", "visioninapp-bucket")

# ------------------------ ìœ í‹¸ ------------------------

def _clean_str(val: Any) -> str | None:
    if val is None:
        return None
    if isinstance(val, str):
        s = val.strip()
        if not s or s.lower() in ("null", "none"):
            return None
        return s
    # strì´ ì•„ë‹ˆì–´ë„ ë“¤ì–´ì˜¤ë©´ ë¬¸ìì—´ë¡œ ìºìŠ¤íŒ…
    s = str(val).strip()
    return s or None


def _select_model_from_params(params: Dict[str, Any]) -> str | None:
    """
    ëª¨ë¸ ì´ë¦„ ì„ íƒ ê·œì¹™:
    1) model
    2) model_name
    3) model_variant
    4) model_varient (ì˜¤íƒ€ ëŒ€ì‘)
    ìœ„ ìˆœì„œëŒ€ë¡œ ìœ íš¨í•œ ê°’ì„ ì°¾ëŠ”ë‹¤.
    """
    for key in ("model", "model_name", "model_variant"):
        v = _clean_str(params.get(key))
        if v:
            return v
    return None

def _merge_train_params(state: TrainState) -> Dict[str, Any]:
    cfg = state.train_cfg or {}

    base = (cfg.get("train") or {}).copy()
    best = ((state.best_trial or {}).get("params") or {}).copy()
    over = (state.train_overrides or {}).copy()

    # ë¨¼ì € base/best/overë¥¼ í•œ ë° í•©ì¹˜ê³ 
    merged = {**base, **best, **over}

    # ğŸ”¹ ì—¬ê¸°ì„œ ëª¨ë¸ ì´ë¦„ì„ ì•ˆì •ì ìœ¼ë¡œ ë½‘ëŠ”ë‹¤
    selected_model = _select_model_from_params(merged)
    if selected_model:
        merged["model"] = selected_model
    else:
        # ìœ íš¨í•œ ê°’ì´ ì§„ì§œë¡œ í•˜ë‚˜ë„ ì—†ì„ ë•Œë§Œ ê¸°ë³¸ê°’ ì‚¬ìš©
        merged["model"] = "yolo12n"

    # ê¸°ë³¸ê°’ë“¤ (ì´ë¯¸ ê°’ ìˆìœ¼ë©´ ê±´ë“¤ì§€ ì•ŠìŒ)
    merged.setdefault("epochs", 100)
    merged.setdefault("batch", 16)
    merged.setdefault("imgsz", 640)

    # None / "null" ë“±ì€ ê¹”ë”í•˜ê²Œ ì œê±°
    cleaned = {}
    for k, v in merged.items():
        if isinstance(v, str):
            vv = v.strip()
            if not vv or vv.lower() in ("null", "none"):
                continue
            cleaned[k] = vv
        elif v is not None:
            cleaned[k] = v

    return cleaned


def _infer_dataset(state: TrainState) -> Dict[str, str]:
    over = state.train_overrides or {}
    if isinstance(over.get("dataset"), dict):
        ds = over["dataset"]
        name = str(ds.get("name") or "").strip()
        s3_prefix = str(ds.get("s3_prefix") or "").strip()
        if name and s3_prefix:
            return {"name": name, "s3_prefix": s3_prefix}

    cfg = state.train_cfg or {}
    data_cfg = cfg.get("data") or {}
    ver = (state.dataset_version or data_cfg.get("dataset_version") or "").strip()
    name = ver.split("@")[0] if "@" in ver else (ver or "dataset").strip()
    if not name:
        name = "dataset"
    return {"name": name, "s3_prefix": f"datasets/{name}/"}


def _infer_output(state: TrainState, dataset_name: str) -> Dict[str, str]:
    over = state.train_overrides or {}
    if isinstance(over.get("output"), dict):
        out = over["output"]
        prefix = str(out.get("prefix") or "").strip()
        model_name = str(out.get("model_name") or "").strip()
        metrics_name = str(out.get("metrics_name") or "").strip() or "results.csv"
        if prefix and model_name:
            return {"s3_bucket": S3_BUCKET, "prefix": prefix, "model_name": model_name, "metrics_name": metrics_name}

    return {
        "prefix": f"models/{dataset_name}/train",
        "model_name": f"{dataset_name}.pt",
        "metrics_name": "results.csv",
    }


# ------------------- RabbitMQ í†µì‹  -------------------

def _publish_to_rabbitmq(message: Dict[str, Any]) -> None:
    import pika

    params = pika.URLParameters(RABBITMQ_URL)
    conn = pika.BlockingConnection(params)
    ch = conn.channel()

    # ìš”ì²­ì€ cmd exchangeë¡œ
    ch.exchange_declare(exchange=EXCHANGE_CMD, exchange_type="topic", durable=True)

    body = json.dumps(message, ensure_ascii=False).encode("utf-8")
    ch.basic_publish(
        exchange=EXCHANGE_CMD,
        routing_key=RK_START,
        body=body,
        properties=pika.BasicProperties(
            delivery_mode=2,
            content_type="application/json",
        ),
    )
    conn.close()



def _wait_for_done(job_id: str, timeout_sec: int = 10800) -> Dict[str, Any]:
    """
    GPU ì„œë²„ê°€ events exchange (EXCHANGE_EVENTS)ì—
    job.{job_id}.done ë©”ì‹œì§€ë¥¼ ë³´ë‚¼ ë•Œê¹Œì§€ ëŒ€ê¸°
    """
    import pika

    params = pika.URLParameters(RABBITMQ_URL)
    conn = pika.BlockingConnection(params)
    ch = conn.channel()

    # âœ… done/progress ëŠ” events exchange ì—ì„œ ì˜¨ë‹¤
    ch.exchange_declare(exchange=EXCHANGE_EVENTS, exchange_type="topic", durable=True)

    q = ch.queue_declare(queue="", exclusive=True, auto_delete=True)
    qname = q.method.queue

    rk_done = RK_DONE_FMT.format(job_id=job_id)
    ch.queue_bind(exchange=EXCHANGE_EVENTS, queue=qname, routing_key=rk_done)

    deadline = time.monotonic() + timeout_sec
    result_payload = None

    for method, properties, body in ch.consume(qname, inactivity_timeout=1.0):
        if method is None:
            if time.monotonic() > deadline:
                break
            continue

        try:
            data = json.loads(body.decode("utf-8"))
        except Exception:
            data = {"status": "error", "error": "invalid JSON"}

        # Progress.done êµ¬ì¡°ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
        if (
            str(data.get("job_id")) == job_id
            and data.get("event") == "done"
        ):
            result_payload = data
            ch.basic_ack(method.delivery_tag)
            break

        ch.basic_ack(method.delivery_tag)

    ch.queue_unbind(exchange=EXCHANGE_EVENTS, queue=qname, routing_key=rk_done)
    conn.close()

    if result_payload is None:
        return {
            "job_id": job_id,
            "status": "timeout",
            "error": "no done event received",
        }
    return result_payload



# ------------------- ë©”ì¸ ë…¸ë“œ -------------------

def train_trial(state: TrainState) -> TrainState:
    """
    EC2 â†’ GPU í•™ìŠµ ìš”ì²­ ë°œí–‰ ì „ìš©
    ì ˆëŒ€ í•™ìŠµ ìˆ˜í–‰ ê¸ˆì§€. ë©”ì‹œì§€ êµ¬ì¡°ëŠ” GPU ì„œë²„ ìš”êµ¬ì‚¬í•­ì— ë§ì¶¤.
    """
    job_id = (state.job_id or str(uuid.uuid4())).replace(" ", "")
    merged = _merge_train_params(state)
    ds = _infer_dataset(state)
    out = _infer_output(state, ds["name"])

    # split ì •ë³´ê°€ ìˆìœ¼ë©´ ì¶”ê°€
    over = state.train_overrides or {}

    if "model" not in over:
        if "model_name" in over:
            over["model"] = over["model_name"]
        elif "model_variant" in over:
            over["model"] = over["model_variant"]

    state.train_overrides = over

    split = over.get("split")
    split_seed = over.get("split_seed")
    move_files = over.get("move_files")

    payload = {
        "job_id": job_id,
        "dataset": ds,
        "output": out,
        "hyperparams": merged,     # GPUê°€ í•™ìŠµ ì‹œ ì‚¬ìš©í•  íŒŒë¼ë¯¸í„°
    }

    # optional fields
    if split is not None:
        payload["split"] = split
    if split_seed is not None:
        payload["split_seed"] = split_seed
    if move_files is not None:
        payload["move_files"] = move_files
    print(payload)
    # 1ï¸âƒ£ í•™ìŠµ ìš”ì²­ ë°œí–‰
    _publish_to_rabbitmq(payload)

    # 2ï¸âƒ£ ì™„ë£Œ ì´ë²¤íŠ¸ ëŒ€ê¸° (job.{job_id}.done)
    wait_sec = int(os.getenv("TRAIN_WAIT_TIMEOUT_SEC", "10800"))
    result = _wait_for_done(job_id, wait_sec)

    # 3ï¸âƒ£ ê²°ê³¼ ë°˜ì˜
    ctx = state.context or {}
    ctx["train_trial"] = {
        "exchange": EXCHANGE_CMD,
        "rk_start": RK_START,
        "rk_done": RK_DONE_FMT.format(job_id=job_id),
        "payload": payload,
        "result": result,
    }
    state.context = ctx
    state.job_id = job_id

    # 4ï¸âƒ£ ê²°ê³¼ ìƒíƒœ ì •ë¦¬
    if result.get("event") == "done":
        artifact = result.get("artifact") or {}
        metrics = result.get("metrics") or {}
        state.model_path = artifact.get("model_path") or artifact.get("s3_path")
        state.metrics = metrics
        state.action = "TRAIN_COMPLETED"
        return state

    elif result.get("status") == "timeout":
        state.action = "TRAIN_TIMEOUT"
        state.error = result.get("error")
        return state

    else:
        state.action = "TRAIN_FAILED"
        state.error = result.get("error") or "unknown error"
        return state
